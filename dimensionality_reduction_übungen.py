# -*- coding: utf-8 -*-
"""Dimensionality_Reduction_Übungen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VOWDQ9g5JwK5hQUdsypRQ38OQq_CwD72
"""

from google.colab import drive
drive.mount('/content/drive')

# 1. Daten importieren
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import numpy as np

# Lade die Daten
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Big_Data/Big_Data_Übungen/02_house_prices.csv')

# 2. DataFrame einschränken auf numerische Features
numerical_data = data.select_dtypes(include=[np.number])

# 3. DataFrame filtern auf Features ohne fehlende Werte
clean_data = numerical_data.dropna(axis=1)

# Zeige alle Spaltennamen, um den Namen der Zielvariable zu finden
print(data.columns)

# Features und Zielvariable definieren (z.B. wenn die Zielvariable 'SalePrice' heißt)
X = clean_data.drop('SalePrice', axis=1)  # Features
y = clean_data['SalePrice']  # Zielvariable

# Daten in Trainings- und Testdaten aufteilen
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Model trainieren mit Linearer Regression
model = LinearRegression()
model.fit(X_train, y_train)

# 5. Berechnen des Root Mean Squared Error (RMSE)
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f'RMSE ohne PCA: {rmse}')

# 6. Zentriere die Daten um den Mittelwert = 0
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 7. Wende PCA an, um die Dimensionen auf 15 zu reduzieren
pca = PCA(n_components=15)
X_pca = pca.fit_transform(X_scaled)

# Splitte die PCA-Daten in Trainings- und Testdaten
X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)

# Model erneut trainieren mit den PCA-Daten
model_pca = LinearRegression()
model_pca.fit(X_train_pca, y_train_pca)

# Vorhersagen machen und RMSE berechnen
y_pred_pca = model_pca.predict(X_test_pca)
rmse_pca = np.sqrt(mean_squared_error(y_test_pca, y_pred_pca))
print(f'RMSE mit PCA: {rmse_pca}')

# Vergleich der Ergebnisse
if rmse_pca < rmse:
    print("Das Modell mit PCA hat sich verbessert.")
else:
    print("Das Modell ohne PCA ist besser.")

"""# **Übung 2**

1- Importieren des MNIST-Datensatzes: Der Datensatz "MNIST" enthält handgeschriebene Ziffern (0-9), die in Form von Bildern vorliegen. Mit einem Befehl aus der Bibliothek Scikit-Learn laden wir diesen Datensatz.
"""

# 1. Importieren des MNIST-Datasets von Scikit-Learn
from sklearn.datasets import fetch_openml
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# MNIST-Dataset laden
df = fetch_openml("mnist_784", parser='auto')

"""2- Features in ein neues DataFrame schreiben: Wir extrahieren die Bilderdaten aus dem Datensatz und speichern sie in einer Variable X. Diese Bilder bestehen aus vielen Zahlen, die beschreiben, wie das Bild aussieht."""

# 2. Schreibe die Features in ein neues DataFrame x
X = df['data']

"""3- Zielvariable in ein neues DataFrame schreiben: Wir speichern die Zahlen, die die Bilder darstellen (also welche Ziffer das Bild zeigt), in einer anderen Variablen y. Dies ist das, was das Modell später vorhersagen soll."""

# 3. Schreibe die Zielvariable in ein neues DataFrame
y = df['target']

# Splitte die Daten in Trainings- und Testsets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""4- Daten in Trainings- und Testdaten aufteilen: Wir teilen den Datensatz in zwei Teile auf: einen zum Trainieren des Modells (80% der Daten) und einen zum Testen (20% der Daten). So können wir sehen, wie gut das Modell lernt."""

# 4. Trainiere das Model mit einem RandomForestClassifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Vorhersagen auf dem Testset
y_pred = model.predict(X_test)

"""5- Trainiere das Modell mit einem RandomForestClassifier: Wir verwenden einen Algorithmus namens "Random Forest", um das Modell zu trainieren. Dieser Algorithmus versucht zu lernen, wie man die Ziffern auf den Bildern erkennt."""

# 5. Berechne Accuracy, Precision, Recall und F1-Score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy ohne PCA: {accuracy}")
print(f"Precision ohne PCA: {precision}")
print(f"Recall ohne PCA: {recall}")
print(f"F1-Score ohne PCA: {f1}")

"""6- Vorhersagen auf dem Testset: Nachdem das Modell trainiert ist, verwenden wir es, um auf den Testdaten (den 20%) Vorhersagen zu machen, welche Ziffer auf jedem Bild ist."""

# 6. Zentriere die Daten um den Mittelwert = 0
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""7- Berechne Accuracy, Precision, Recall und F1-Score: Jetzt berechnen wir, wie gut das Modell funktioniert. Dafür gibt es verschiedene Messwerte:

+ Accuracy: Wie viele der Vorhersagen waren richtig?
+ Precision: Wie präzise sind die Vorhersagen für jede Ziffer?
+ Recall: Wie viele der tatsächlichen Ziffern hat das Modell richtig erkannt?
+ F1-Score: Eine Kombination aus Precision und Recall.
"""

# 7. Wende PCA an, aber nutze weiterhin alle 784 Features
pca = PCA(n_components=784)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Trainiere das Modell mit den PCA-Daten (alle Features)
model_pca_all = RandomForestClassifier(random_state=42)
model_pca_all.fit(X_train_pca, y_train)

# Vorhersagen auf dem Testset mit PCA (alle Features)
y_pred_pca_all = model_pca_all.predict(X_test_pca)

"""8- Daten um den Mittelwert zentrieren: Um die Daten besser verarbeiten zu können, zentrieren wir sie um den Mittelwert (setzen den Durchschnitt auf 0). Das hilft bei einigen mathematischen Verfahren."""

# 8. Berechne Accuracy, Precision, Recall und F1-Score mit PCA (alle Features)
accuracy_pca_all = accuracy_score(y_test, y_pred_pca_all)
precision_pca_all = precision_score(y_test, y_pred_pca_all, average='weighted')
recall_pca_all = recall_score(y_test, y_pred_pca_all, average='weighted')
f1_pca_all = f1_score(y_test, y_pred_pca_all, average='weighted')

print(f"Accuracy mit PCA (alle Features): {accuracy_pca_all}")
print(f"Precision mit PCA (alle Features): {precision_pca_all}")
print(f"Recall mit PCA (alle Features): {recall_pca_all}")
print(f"F1-Score mit PCA (alle Features): {f1_pca_all}")

"""**9- PCA anwenden (mit allen 784 Features): Jetzt wenden wir ein Verfahren namens PCA (Principal Component Analysis) an, das die Daten so umwandelt, dass sie kompakter sind, ohne Informationen zu verlieren. Hier behalten wir alle 784 Merkmale (Features), die ein Bild ausmachen.**"""

# 9. Wende PCA an, um die Dimensionen auf 326 zu reduzieren
pca_326 = PCA(n_components=326)
X_train_pca_326 = pca_326.fit_transform(X_train_scaled)
X_test_pca_326 = pca_326.transform(X_test_scaled)

# Trainiere das Modell mit den PCA-Daten (326 Features)
model_pca_326 = RandomForestClassifier(random_state=42)
model_pca_326.fit(X_train_pca_326, y_train)

# Vorhersagen auf dem Testset mit PCA (326 Features)
y_pred_pca_326 = model_pca_326.predict(X_test_pca_326)

"""**10- Wiederhole den Trainingsprozess mit den PCA-Daten: Wir trainieren das Modell erneut mit den kompakteren PCA-Daten und berechnen wieder die Messwerte (Accuracy, Precision, Recall, F1-Score).**

PCA anwenden (auf 326 Features reduzieren): Diesmal reduzieren wir die Anzahl der Merkmale auf 326. Das bedeutet, dass wir das Bild mit weniger Informationen beschreiben, aber versuchen, die wichtigsten Teile zu behalten.

Trainiere das Modell mit den reduzierten Daten und berechne die Messwerte: Wir wiederholen den gesamten Prozess noch einmal mit den auf 326 Merkmale reduzierten Daten und berechnen erneut die Messwerte.
"""

# 10. Berechne erneut die Kennzahlen Accuracy, Precision, Recall und F1-Score mit PCA (326 Features)
accuracy_pca_326 = accuracy_score(y_test, y_pred_pca_326)
precision_pca_326 = precision_score(y_test, y_pred_pca_326, average='weighted')
recall_pca_326 = recall_score(y_test, y_pred_pca_326, average='weighted')
f1_pca_326 = f1_score(y_test, y_pred_pca_326, average='weighted')

print(f"Accuracy mit PCA (326 Features): {accuracy_pca_326}")
print(f"Precision mit PCA (326 Features): {precision_pca_326}")
print(f"Recall mit PCA (326 Features): {recall_pca_326}")
print(f"F1-Score mit PCA (326 Features): {f1_pca_326}")

"""**Frage: Wie haben sich die Kennzahlen verändert?
Beim Vergleich der Kennzahlen (Accuracy, Precision, Recall, F1-Score) zwischen:**

+ Dem Modell ohne PCA.
+ Dem Modell mit PCA und allen 784 Features.
+ Dem Modell mit PCA und 326 Features.


---


PCA (alle 784 Features) sollte ähnliche oder leicht verbesserte Ergebnisse liefern, da wir keine Informationen verloren haben, aber die Daten möglicherweise besser organisiert sind.


---


PCA (326 Features) könnte leicht schlechtere Ergebnisse liefern, da wir einige Details der Bilder entfernt haben. Das Modell hat jetzt weniger Informationen zur Verfügung, um die Ziffern korrekt zu identifizieren, was zu einem geringeren Accuracy, Precision, Recall, und F1-Score führen kann.
"""